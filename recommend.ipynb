{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam video game recommendation\n",
    "The objective of the project is to try to fit a base game (when it is divided into training and testing) in one of the audience approval categories that will be created by me during the project, based on approval percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing some categories that I thought were unnecessary\n",
    "decided to remove the genres because when I was going to use One Hot Encoding it would be a very polluted base by several columns, which would delay the analysis even more\n",
    "I also thought that the studio that developed the games would be more relevant than their publisher, so I removed the publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data = pd.read_csv('steam.csv')\n",
    "# print(steam_data.columns)\n",
    "steam_data = steam_data.drop(columns=['appid','name','price','categories','english', 'achievements','required_age' , 'release_date', 'developer','publisher', 'platforms', 'steamspy_tags'])\n",
    "print(steam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seems we have a lot of unique values for the genres, we need to do some feature engineering\")\n",
    "steam_data.genres.unique().shape[0] , steam_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = []\n",
    "for string in steam_data.genres.unique():\n",
    "    tmp_genres = string.split(\";\")\n",
    "    for genre in tmp_genres:\n",
    "        if genre not in genres:\n",
    "            genres.append(genre)\n",
    "\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data = steam_data.reindex(columns=list(steam_data.columns)+genres)\n",
    "steam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = steam_data.index\n",
    "\n",
    "for i, string in zip(ids, steam_data.genres):\n",
    "    tmp_genres = string.split(\"|\")\n",
    "    for genre in genres:\n",
    "        if genre  in tmp_genres:\n",
    "            steam_data.at[i, genre] = 1\n",
    "        else :\n",
    "            steam_data.at[i, genre] = 0\n",
    "\n",
    "steam_data.drop(columns=\"genres\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres:\n",
    "    steam_data[genre] = pd.to_numeric(steam_data[genre], downcast=\"integer\")\n",
    "\n",
    "steam_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the median of the estimated number of game owners and replacing the values ​​in the 'owners' column with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "owners = steam_data['owners']\n",
    "owners_median = []\n",
    "\n",
    "for i in owners:\n",
    "    #splitting the strings in two for each element in the 'owners' column, which are normally represented by a string \"initial value - final value\"\n",
    "    temp = i.split('-')\n",
    "\n",
    "    #now transforming string elements into integers using list comprehension\n",
    "    elements = [int(elemento) for elemento in temp]\n",
    "\n",
    "    #inverting the order of elements, to put the maximum estimated value of owners before the minimum value\n",
    "    invert = elements[::-1]\n",
    "\n",
    "    #taking the median of the two values ​​and adding to a new list\n",
    "    mediana = statistics.median(invert)\n",
    "    owners_median.append(float(mediana))\n",
    "\n",
    "owner_df = pd.DataFrame(owners_median, columns = ['median_of_owners'])\n",
    "\n",
    "steam_data = steam_data.drop(['owners'], axis = 1)\n",
    "steam_data = steam_data.join(owner_df['median_of_owners'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning categories into binary numbers\n",
    "\"\"\"\n",
    "Knowing that the \"categories\" column is used to say what type of game itself, I will first find out how many categories are possible\n",
    "\n",
    "Then I'll turn all the categories into just two, single and multiplayer. This will serve to simplify the analysis\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categories = steam_data['categories']\n",
    "strings = []\n",
    "\n",
    "\"\"\"\n",
    "  There are some cases where a game can have multiple categories, and in those cases, they are separated by ';', so I'll break them down by that.\n",
    "\"\"\"\n",
    "\n",
    "for element in categories:\n",
    "    strings.append(element.split(';'))\n",
    "\n",
    "#the list 'strings' is made up of lists of strings. Variable 'temp2' will only have strings, no lists inside\n",
    "temp = [element for element in strings]\n",
    "temp_list = []\n",
    "\n",
    "for element in temp:\n",
    "    temp_list.extend(element)\n",
    "\n",
    "#eliminating duplicate elements by transforming to set\n",
    "categories_set = set(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categories_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The categories were organized like this:\n",
    "\n",
    "Multiplayer (here will also fit the categories: Co-op, Online Co-op, Online Multi-Player, Cross-Platform Multiplayer, Local Multi-Player, Local Co-op, Shared/Split Screen, and MMO);\n",
    "\n",
    "Singleplayer;\n",
    "\n",
    "Hybrid (if the game has the option to be played both multiplayer and singleplayer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following loop will check if a game is hybrid, single-player, or multi-player, and add the right category for each game to 'new_changed_list'\n",
    "multiplayer = ['Multi-player', 'Co-op', 'Online Co-op', 'Online Multi-Player', 'Cross-Platform Multiplayer', 'Local Multi-Player', 'Local Co-op', 'Shared/Split Screen', 'MMO']\n",
    "\n",
    "condensed_category = []\n",
    "\n",
    "for i in range(len(temp_list)):\n",
    "    for multiplayer_element in multiplayer:\n",
    "        if 'Single-player' in temp_list[i] and multiplayer_element in temp_list[i]:\n",
    "            condensed_category.append('Hybrid')\n",
    "            break\n",
    "        elif multiplayer_element in temp_list[i]:\n",
    "            condensed_category.append('Multiplayer')\n",
    "            break\n",
    "        elif multiplayer_element not in temp_list[i]:\n",
    "            condensed_category.append('Singleplayer')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the old category column with the new one\n",
    "new_category = pd.DataFrame(condensed_category, columns = ['categories'])\n",
    "\n",
    "steam_data = steam_data.drop(columns=['categories'], axis=1)\n",
    "steam_data = steam_data.join(new_category['categories'])\n",
    "print(steam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(steam_data[['categories']]).toarray())\n",
    "steam_data = steam_data.join(enc_df)\n",
    "steam_data = steam_data.drop(columns=['categories'], axis=1)\n",
    "print(steam_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the positive_ratings and negative_ratings columns into one, which will be expressed as a percentage. Also, I will only select the games that have more ratings (quantity) than 100 (this number can be changed)\n",
    "\n",
    "\n",
    "Example:\n",
    "If the game has 70 upvotes and 30 downvotes, the new column will have \"70\" as its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = steam_data['positive_ratings']\n",
    "nr = steam_data['negative_ratings']\n",
    "ratings = pr+nr\n",
    "\n",
    "#Selecting only the lines above X ratings, the value can be changed below\n",
    "x = 100\n",
    "\n",
    "ratings = pd.DataFrame(ratings, columns=['ratings'])\n",
    "\n",
    "steam_data = steam_data.join(ratings['ratings'])\n",
    "lista_av = []\n",
    "\n",
    "for i in range(len(steam_data)):\n",
    "    if steam_data['ratings'][i] < x: #change this number 100 if you want to decrease or increase the base\n",
    "        lista_av.append(i)\n",
    "\n",
    "steam_data = steam_data.drop(lista_av)\n",
    "\n",
    "#creating the percentage column\n",
    "\n",
    "pr = steam_data['positive_ratings']\n",
    "nr = steam_data['negative_ratings']\n",
    "ratings = pr+nr\n",
    "\n",
    "ratings = tuple(ratings)\n",
    "pr = tuple(pr)\n",
    "\n",
    "assessments = []\n",
    "\n",
    "#taking the percentage of 'approval' (positive votes versus negative votes)\n",
    "for i in range(len(steam_data)):\n",
    "    res = pr[i] * 100 / ratings[i]\n",
    "    assessments.append(res)\n",
    "\n",
    "steam_data = steam_data.drop(columns=['positive_ratings', 'negative_ratings', 'ratings'], axis = 1)\n",
    "\n",
    "steam_data['ratings'] = assessments\n",
    "\n",
    "steam_data = steam_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I will mark the following categories for the evaluations, based on the previous process:\n",
    "\n",
    "Horrible: ratings < 40%\n",
    "\n",
    "Bad: 40% <= ratings < 55%\n",
    "\n",
    "Median: 55% <= ratings < 70%\n",
    "\n",
    "Good: 70% <= ratings < 90%\n",
    "\n",
    "Great: ratings >= 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking different categories for reviews\n",
    "steam_data.reset_index(drop=True, inplace=True)\n",
    "rt = steam_data['ratings']\n",
    "\n",
    "\n",
    "#basically the following loops will assign different categories to the evaluations, and these categories will be used as the target attribute of the AIs\n",
    "\n",
    "#transforming ratings into floats numbers and saving to a list\n",
    "float_ratings = []\n",
    "for i in range(len(steam_data)):\n",
    "  float_ratings.append(float(steam_data['ratings'][i]))\n",
    "\n",
    "rt_temp = []\n",
    "\n",
    "for i in range(len(steam_data)):\n",
    "    if float_ratings[i] < 40:\n",
    "        rt_temp.append(0)\n",
    "    elif float_ratings[i] >= 40 and float_ratings[i] < 55:\n",
    "        rt_temp.append(1)\n",
    "    elif float_ratings[i] >= 55 and float_ratings[i] < 70:\n",
    "        rt_temp.append(2)\n",
    "    elif float_ratings[i] >= 70 and float_ratings[i] < 90:\n",
    "        rt_temp.append(3)\n",
    "    elif float_ratings[i] >= 90:\n",
    "        rt_temp.append(4)\n",
    "\n",
    "steam_data = steam_data.drop(columns=['ratings'], axis=1)\n",
    "steam_data['ratings'] = rt_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the base into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = steam_data.drop(['ratings','average_playtime','median_playtime','median_of_owners'], axis = 1)\n",
    "y = steam_data['ratings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNModel = KNeighborsClassifier(p=2, n_neighbors=15, weights = 'distance', algorithm = 'auto')\n",
    "KNNModel.fit(X_train, y_train)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = KNNModel.predict(X_train)\n",
    "print('Target on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = KNNModel.predict(X_test)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "nbscore = accuracy_score(y_test,predict_test)\n",
    "print('accuracy_score on test dataset : ',nbscore)\n",
    "\n",
    "\n",
    "# f, axes = plt.subplots(1, 2, figsize=(30, 12))\n",
    "# pred = confusion_matrix(y_train, predict_train)\n",
    "\n",
    "# sb.heatmap(pred, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "# sb.heatmap(confusion_matrix(y_test, predict_test), \n",
    "#            annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set(color_codes=True)\n",
    "sb.set(font_scale=1.4)\n",
    "\n",
    "plt.figure(1, figsize=(30, 12))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "train = sb.heatmap(confusion_matrix(y_train, predict_train), annot=True, fmt=\".0f\",cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "train.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 7)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "\n",
    "nbscore = accuracy_score(y_test,predict_test)\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", accuracy_train)\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", nbscore)\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set(color_codes=True)\n",
    "sb.set(font_scale=1.4)\n",
    "\n",
    "plt.figure(1, figsize=(30, 12))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "train = sb.heatmap(confusion_matrix(y_train, predict_train), annot=True, fmt=\".0f\",cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "train.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
